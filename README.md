# Contextual Answering System with Multi-Source Integration

Este proyecto implementa un sistema inteligente de respuesta a preguntas que combina m煤ltiples fuentes de informaci贸n (consultas SQL, recuperaci贸n por embeddings, entre otras) para generar un contexto preciso y relevante. Este contexto es procesado y enriquecido por un modelo de lenguaje (LLM), permitiendo responder preguntas complejas y espec铆ficas sobre la informaci贸n interna de una empresa.

---

##  Objetivo

Permitir a los usuarios realizar consultas espec铆ficas sobre los datos de una organizaci贸n, utilizando informaci贸n dispersa y estructurada desde distintas fuentes, y generando respuestas precisas mediante un modelo LLM (Large Language Model).

---

##  驴C贸mo funciona?

1. **Recepci贸n de la pregunta del usuario**
2. **Clasificaci贸n y an谩lisis de intenci贸n** para determinar qu茅 tipo de datos son necesarios (bases SQL, documentos, embeddings, etc.)
3. **Recuperaci贸n de informaci贸n** desde:
   - Bases de datos relacionales (v铆a SQL)
   - Vector stores (usando embeddings sem谩nticos)
   - Otras APIs o sistemas documentales
4. **Construcci贸n del contexto** unificado a partir de los resultados recuperados.
5. **Generaci贸n de respuesta** utilizando un LLM (como GPT, LLaMA o similar) alimentado con el contexto.
6. **Entrega de la respuesta enriquecida y precisa** al usuario.

---

## П Arquitectura

```text
[User Question]
      |
      v
[Intenci贸n + Extracci贸n de entidades]
      |
      v
[Recuperaci贸n de contexto] <---- SQL / Embeddings / APIs
      |
      v
[Construcci贸n de prompt]
      |
      v
[LLM (GPT, LLaMA, etc.)]
      |
      v
[Respuesta final]
